{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bse_own_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/iitpbse/blob/master/dl/d2/bse_own_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG60mf0hnabS"
      },
      "source": [
        "**Image classification using our own data with Keras\n",
        "\n",
        "\n",
        "\n",
        "> Make sure that the data (with which you would like to perform classification) is available in your Google Drive\n",
        "\n",
        "> Data used in this example, is a subset of Kaggle dataset (available @ https://www.microsoft.com/en-us/download/details.aspx?id=54765)\n",
        "\n",
        "> You can download the dataset which is available at the above mentioned link. Alternatively, you can download the dataset from the link https://github.com/nrjcs/mlip/raw/master/d4/img_data_kaggle.zip\n",
        "\n",
        "> In any case, the dataset (images and not the compressed file) must be uploaded in your google drive  in the directory \"img_data\"...if you would like to put the data in different directory then update ip_path variable in incoming cell \n",
        "\n",
        "> Data consists of 100 images of cats and dogs each\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ZtEfocDOM3"
      },
      "source": [
        "#intialization \n",
        "train_labels=[]\n",
        "train_samples=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRYIlF14q7Jg"
      },
      "source": [
        "**load the Drive helper and mount**\n",
        "\n",
        "following code cell is to link your drive with Colab...the procedure for the same is as follows:\n",
        "\n",
        "> execute this code cell -> click the link that you will get as output -> select the account to sign with which the Google Drive is associated -> copy the code -> (switch back to this page) -> paste the copied code in the box following the message \"Enter your authorization code:\" in the output pane on execution of following code you will get a link -> press enter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGk80apX4d_W"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDV0p8-ER5ub"
      },
      "source": [
        "!ls \"/content/drive/My Drive/img_data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXChPMPeAbGt"
      },
      "source": [
        "- Create a directory named \"img_data_updated\" to store the converted images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paej5JhOn95D"
      },
      "source": [
        "!ls \"/content/drive/My Drive/img_data_updated/\" # the colored images are converted and stored in this directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmNFFTSuDOM6"
      },
      "source": [
        "# initialization of input and output paths of images\n",
        "ip_path='/content/drive/My Drive/img_data/'\n",
        "op_path='/content/drive/My Drive/img_data_updated/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHJe8s_YDOM8"
      },
      "source": [
        "import os # Miscellaneous operating system interfaces...file and directory related operations among others\n",
        "from numpy import * #package for scientific computing\n",
        "\n",
        "#getting list of images\n",
        "listing=os.listdir(ip_path) #list of the names of the entries in the arg (directory)\n",
        "num_samples=size(listing)\n",
        "print(num_samples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAPNp8nLDONA"
      },
      "source": [
        "#intiatialization\n",
        "img_rows, img_cols=64, 64\n",
        "channels=1\n",
        "\n",
        "\n",
        "from PIL import Image # PIL is the Python Imaging Library ....adds image processing capabilities to your Python interpreter....visit https://pillow.readthedocs.io/en/stable/\n",
        "#image preprocessing...resize...convert to grayscale....and save to output directory\n",
        "for file in listing:\n",
        "    im=Image.open(ip_path+'/'+file)\n",
        "    img=im.resize((img_rows,img_cols))\n",
        "    gray=img.convert('L')\n",
        "    gray.save(op_path+'/'+file, \"JPEG\")\n",
        "imlist=os.listdir(op_path)  \n",
        "print (imlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUrHB0fnzQoc"
      },
      "source": [
        "# sort....\n",
        "imlist.sort(key=lambda f: int(filter(str.isdigit, f)))\n",
        "print (imlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5leVRPucDONE"
      },
      "source": [
        "# viewing images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im1=array(Image.open('/content/drive/My Drive/img_data_updated/'+imlist[0]))\n",
        "plt.imshow(im1)\n",
        "#plt.imshow(im1,cmap='gray')\n",
        "print(im1.shape)\n",
        "m,n=im1.shape[0:2]\n",
        "print m,m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAh-1zL3DONH"
      },
      "source": [
        "#flatten all the images into one matrix\n",
        "img_mat=array([array(Image.open('/content/drive/My Drive/img_data_updated/'+imseq)).flatten() \n",
        "           for imseq in imlist],'f')\n",
        "\n",
        "#print img_mat\n",
        "#print img_mat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb8GRTzyDONK"
      },
      "source": [
        "import numpy as np\n",
        "# initialize labels\n",
        "labels=np.ones((num_samples),dtype=int)\n",
        "print labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll11SzTtDONO"
      },
      "source": [
        "#reset labels\n",
        "labels[0:100]=0\n",
        "labels[100:200]=1\n",
        "print labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaANglgADONR"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "#make sample label pairs\n",
        "data,label=shuffle(img_mat,labels)\n",
        "#for i in range(200):\n",
        "#   print data[i],label[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxpJhW8DONU"
      },
      "source": [
        "#combine data and labels as single input\n",
        "\n",
        "#this step in not necessary as we can input the data and label as two arrarys\n",
        "train_data=[data,label]\n",
        "print train_data[0].shape #shape of samples\n",
        "\n",
        "print train_data[1].shape #shape of labels\n",
        "print train_data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxEmOXMkDONY"
      },
      "source": [
        "#check the images from the flattened matrix\n",
        "check_img=img_mat[11].reshape(img_rows,img_cols)\n",
        "plt.imshow(check_img)\n",
        "plt.imshow(check_img,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MKhIS3vAuW9"
      },
      "source": [
        "(X,Y)=(train_data[0],train_data[1])  \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# preprocessing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1, random_state=4)\n",
        "\n",
        "X_temp = X_test\n",
        "\n",
        "print (X_train.shape)\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image and pixel precision set to 32 bit\n",
        "num_pixels = img_rows * img_cols\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "from keras.utils import np_utils\t\t#for transforming data \n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "# check again\t\n",
        "print (Y_train.shape)\n",
        "# (60000, 10)\n",
        "print (Y_train[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcp5iXTAyyZ"
      },
      "source": [
        "input_dim = img_rows * img_cols\n",
        "output_dim = 2\n",
        "# Define model architecture\n",
        "\n",
        "from keras.models import Sequential\t\t#model\n",
        "from keras.layers import Dense\t\t\t#layer\n",
        "from keras.layers import Dropout\t\t#layer\n",
        "from keras import initializers      # for importing initializers of keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim, input_dim=input_dim, kernel_initializer=initializers.RandomNormal(), activation='relu')) #only one hidden layer with relu as activation function\n",
        "#model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer=initializers.Constant(value=5), activation='relu')) #only one hidden layer with relu as activation function\t\n",
        "model.add(Dense(output_dim, kernel_initializer='normal', activation='softmax'))\t\t\t\t\t#output layer with softmax as activation function\n",
        "\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "print (\"congrts model defined...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTavbiQDONw"
      },
      "source": [
        "# compile the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
        "\n",
        "# print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN9bfNJfDON1"
      },
      "source": [
        "#Train model\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "history =model.fit(X_train, Y_train,validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "print (\"parameter tuning done...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKEdH_bmc5nR"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vbhb5emdEQg"
      },
      "source": [
        "# Accuracy with the epochs\n",
        "\n",
        "plt.plot(history.history['accuracy'],'r')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training'], loc='center right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVycUDFZdPKT"
      },
      "source": [
        "# Loss with epochs\n",
        "\n",
        "plt.plot(history.history['loss'],'g')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}