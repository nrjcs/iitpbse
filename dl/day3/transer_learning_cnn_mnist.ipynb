{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transer_learning_cnn_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/foundation_aiml/blob/master/transer_learning_cnn_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV3jpWWaVzxL",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go-Au1mYVzxN",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning is a basic appoach of model reuse and retraining\n",
        "### A model trained on one dataset for a different domain is refined by modifying some of the last layers and training with new dataset\n",
        "    * This saves a lot of training time as we only need to modify some of the layers and retrain only those layers\n",
        "    * Also sometimes we don't have a very big dataset which we can use for training a model so we take pretrained model and retrain it by making only some of the layers trainable\n",
        "    * This is one of the basic techniques for domain adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZMuPsLeVzxP",
        "colab_type": "text"
      },
      "source": [
        "### This is a basic example from keras examples directory\n",
        "(Available @ https://github.com/keras-team/keras/blob/master/examples/mnist_transfer_cnn.py) \n",
        "\n",
        "    * - Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "    * - Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9].\n",
        "   \n",
        "\n",
        "Get to 99.8% test accuracy after 5 epochs\n",
        "for the first five digits classifier\n",
        "and 99.2% for the last five digits after transfer + fine-tuning.\n",
        "### Refer to this link for more on sequential models https://keras.io/getting-started/sequential-model-guide/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq-x20rjVzxQ",
        "colab_type": "code",
        "outputId": "b2d9c298-be84-4679-8d0a-a14c32541add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0d0Wao5VzxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128  # no.of elements to be used for one iteration\n",
        "num_classes = 5   # no. of classes for training\n",
        "epochs = 5        # how many times the whole dataset should be iterated\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size \n",
        "kernel_size = 3  # here kernel_size means a 3x3 filter\n",
        "\n",
        "if K.image_data_format() == 'channels_first':  # channels mean no. of color channels of the image\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)    # tensorflow uses channels_last config by default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7v5c7MuVzxZ",
        "colab_type": "text"
      },
      "source": [
        "### Define the funtion which will run the training with input model and training data \n",
        "    This function basically does some preprocessing on training data and then runs compile and fit functions of keras.models.Sequential "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlhI0XceVzxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    # compile the model\n",
        "    # you can chnage the parameters in this compile function\n",
        "    # custom funtions for loss and opitizer can be used: ref to keras documentation for more\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnJPmvcmVzxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# create two datasets one with digits below 5 and one with 5 and above\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmmlBX6Vzxg",
        "colab_type": "code",
        "outputId": "a224dcdd-807e-42a7-8951-ae60c32947c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 07:03:28.803566 139962742462336 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caNz-QGXVzxj",
        "colab_type": "code",
        "outputId": "9037682a-95fe-484c-f96a-e80f3b7945ee",
        "colab": {}
      },
      "source": [
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/fazy/anaconda2/envs/retnet/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /home/fazy/anaconda2/envs/retnet/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "WARNING:tensorflow:From /home/fazy/anaconda2/envs/retnet/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/5\n",
            "30596/30596 [==============================] - 41s 1ms/step - loss: 0.1624 - acc: 0.9487 - val_loss: 0.0336 - val_acc: 0.9893\n",
            "Epoch 2/5\n",
            "30596/30596 [==============================] - 40s 1ms/step - loss: 0.0474 - acc: 0.9854 - val_loss: 0.0182 - val_acc: 0.9940\n",
            "Epoch 3/5\n",
            "30596/30596 [==============================] - 41s 1ms/step - loss: 0.0335 - acc: 0.9900 - val_loss: 0.0115 - val_acc: 0.9951\n",
            "Epoch 4/5\n",
            "30596/30596 [==============================] - 42s 1ms/step - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0092 - val_acc: 0.9961\n",
            "Epoch 5/5\n",
            "30596/30596 [==============================] - 41s 1ms/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9963\n",
            "Training time: 0:03:26.514314\n",
            "Test score: 0.008760383791646969\n",
            "Test accuracy: 0.9963027826425375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWRUTPmiVzxn",
        "colab_type": "text"
      },
      "source": [
        "### Model trained in the above block can be used for classifying digits 5 to 9 by fine tuning it\n",
        "    For fine tuning we will freeze all the convolutional and maxpooling layers (feature layers)\n",
        "    This can be done by making those layers non-trainable\n",
        "    only the top(last) two layers (dense layers) are left trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQNVmjw1Vzxo",
        "colab_type": "code",
        "outputId": "b9ecea68-88fd-4484-8f95-4d9f7d4e6ad9",
        "colab": {}
      },
      "source": [
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/5\n",
            "29404/29404 [==============================] - 13s 459us/step - loss: 0.2443 - acc: 0.9288 - val_loss: 0.0527 - val_acc: 0.9819\n",
            "Epoch 2/5\n",
            "29404/29404 [==============================] - 13s 431us/step - loss: 0.0778 - acc: 0.9757 - val_loss: 0.0387 - val_acc: 0.9850\n",
            "Epoch 3/5\n",
            "29404/29404 [==============================] - 13s 434us/step - loss: 0.0615 - acc: 0.9815 - val_loss: 0.0288 - val_acc: 0.9901\n",
            "Epoch 4/5\n",
            "29404/29404 [==============================] - 13s 426us/step - loss: 0.0535 - acc: 0.9836 - val_loss: 0.0261 - val_acc: 0.9907\n",
            "Epoch 5/5\n",
            "29404/29404 [==============================] - 13s 433us/step - loss: 0.0463 - acc: 0.9858 - val_loss: 0.0250 - val_acc: 0.9909\n",
            "Training time: 0:01:04.338330\n",
            "Test score: 0.025045440907186217\n",
            "Test accuracy: 0.9909483644236903\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
